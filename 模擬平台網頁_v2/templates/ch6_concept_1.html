{% extends 'layout.html' %}

{% block body %}
{% include 'ch6_top.html' %}
<style type="text/css">

.center {
	display: block;
  	margin-left: auto;
  	margin-right: auto;
}

.questions_zone {
	display: grid;
	grid-template-columns: 1000px;
  	grid-template-rows: 50px 200px;
  	height: 250px;
  	width: 1000px;
	margin-left: auto;
  	margin-right: auto;
  	margin-bottom: 20px;
  	border: 5px #7426E0 solid;
}

.form-group {
	display: block;
	margin-left: 40px;
}

textarea {
	height: 90px;
	width: 800px;
	resize: none;
	font-size: 20px
}

mark {
  background-color: yellow;
  color: black;
}

</style>

<h2>類神經網路如何自動調整權重？</h2>
<p>在先前的單元中，我們認識到<mark>類神經網路以及它的應用</mark>，</p>
<p>我們也深入介紹了<mark>類神經網路中的概念</mark>，像是<mark>「權重」</mark>、<mark>「誤差」</mark>、<mark>「激勵函數」</mark>等，</p>
<p>還記得我們一開始「手動」調整權重嗎？</p>
<p>在這個章節，我們將開始介紹<mark>類神經網路如何「自動」調整權重</mark>。</p>
<p>這時候，先回想一下「調整權重」的目的是什麼？</p>

<div class="questions_zone">
	<h2>思考一下，回答問題</h2>
		<div style="margin-top: 40px;">
			<h3>問題一</h3>
			<p>「調整權重」的目的是什麼？</p>
		</div>
</div>

<p>清楚知道調整權重的目的後，我們來正式開始介紹如何「自動」調整權重吧。</p>
<p>在先前的課程，我們將「誤差」定義為「期望輸出」減去「輸出」，</p>
<p>而如果誤差為正，就需要增加類神經網路的輸出；如果誤差為負，就需要減少類神經網路的輸出，</p>
<p>依照這個想法，<mark>在1958年時，Frank Rosenblatt提出了一種學習演算法</mark>：</p>
<p style="text-align: center; margin-bottom: 0px;">w<sub>i</sub><sup>t+1</sup> = w<sub>i</sub><sup>t</sup> + 𝛼 * x<sub>i</sub> * Error<sup>t</sup></p>
<p style="text-align: center; margin-bottom: 0px;">(演算法中的「Error」即為「誤差」)</p>

<p>這個<mark>演算法主要的設計原理是透過誤差來決定權重需要多少調整，</mark></p>
<p><mark>如果誤差很大，權重調整的幅度就會大，反之則調整幅度就會小</mark>，</p>
<p>而演算法當中的「𝛼 * x<sub>i</sub> * Error<sup>t</sup>」，</p>
<p>就是在每次迭代中，決定權重需要調整多少的計算方式，</p>
<p><mark>𝛼值為「學習率」</mark>，它是一個介在0和1的正數(它通常不會是0)，</p>
<p>可以調整每次權重的調整幅度，而x<sub>i</sub>就是類神經網路的輸入值，</p>


<h2>重點總結</h2>
<p>在本章節中，我們介紹了一種學習演算法，理解它可能要花費一些心思，</p>
<p>在下個章節中，我們會用更簡單的比喻來說明這個演算法，</p>
<p>並且在本章的模擬操作中，我們會再用更實際的案例來運用這個學習演算法，</p>
<p>讓你能夠更加熟悉這個概念。</p>

{% include 'ch6_buttom.html' %}
{% endblock %}